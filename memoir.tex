\documentclass[12pt]{article} \usepackage[utf8x]{inputenc}
\usepackage{graphicx} \usepackage{multirow} \usepackage{hhline}
\usepackage{booktabs} \usepackage{vmargin} %cambia el margen
\usepackage{amsmath,amsthm} \usepackage{amsfonts} \usepackage{float}
\usepackage{listings}


\usepackage[hidelinks]{hyperref}




\title{
  Historia de las Matemáticas\\
  \large Historia de los algoritmos inspirados en la evolución:
  Algoritmos Genéticos, Programación Evolutiva, Estrategias de
  Evolución y Programación Genética.  }


\author{
  Francisco Luque Sánchez \\
  Ignacio Mas Mesa \\
  Miguel Morales Castillo \\
  María del Mar Ruiz Martín \\
}



\begin{document}
\maketitle
\begin{center}  
\includegraphics[scale=0.35]{escudo.png}
\end{center}

\newpage

\tableofcontents % para generar el índice de contenidos

\pagebreak

\section{Introducción}

Las metaheurísticas son una clase de estrategias de resolución de
problemas que aparecieron en los años 50. Este tipo de algoritmos se
inspiran en procesos naturales, físicos o sociales para intentar
resolver problemas, usualmente de optimización, cuando el espacio de
soluciones es demasiado amplio para ser estudiado por métodos
tradicionales.\\

En este trabajo abordaremos, desde una perspectiva histórica, el
origen, evolución y estado actual de este tipo de técnicas, así como
ejemplos prácticos de aplicación. En particular, incidiremos sobre una
clase importante de metaheurísticas, las cuales se inspiran en el
proceso natural de la evolución. Dentro de este grupo se engloban
cuatro enfoques principales, que son los algoritmos genéticos, la
programación evolutiva, la programación genética y las estatregias
de evolución.\\

\section{Metaheurísticas}

Las metaheurísticas aparecieron en los años 50 como respuesta a los
problemas de optimización. Hasta ese momento, los ordenadores habían
sido utilizados como herramientas de ayuda al cálculo, pero no se
habían pensado como máquinas capaces de resolver problemas más
complejos (needs further research). Cuando se intentaron implementar
técnicas de optimización clásica para resolver problemas de búsqueda
(derivación de funciones para el cálculo de extremos locales), se
observó que para muchos problemas este enfoque no era suficiente
(citation needed). Uno de los problemas que surgió fue que las
funciones a optimizar tenían muchos extremos locales, infinitos en
algunos casos. También se encontraron problemas en los que las
funciones a optimizar no eran derivables, por lo que el enfoque
clásico no podía
ser aplicado.\\

Empezaron a aparecer entonces intentos de resolución de problemas de
este tipo con estrategias distintas. El primer ejemplo de este tipo de
estrategias vino en 1951, con un método de aproximación estocástica.
Este método, creado por Herbert Robins y Sutton Monro, trataba de
encontrar extremos de una función utilizando un método de aproximación
por pasos que depende de una variable aleatoria. Así se puede buscar
el mínimo de una función sin tener que buscar la derivada de la misma.\\

Posteriormente, apollándose en los trabajos de Robbins y Monro,
empezaron a aparecer los métodos de búsqueda local. Estos enfoques
consisten en tratar de buscar una solución al problema por medio de
evaluaciones de la función objetivo (función que tratamos de
maximizar). El primer método desarrollado en esta línea fue propuesto
por L. A. Rastrigin, que propuso el algoritmo conocido como
\textit{random search}. Consiste en comenzar evaluando la función
objetivo en un punto aleatorio del espacio de soluciones, y tras esto,
mientras no se haya alcanzado un criterio de parada (se hayan
terminado el número de iteraciones fijadas para el algoritmo, o se
haya alcanzado una cota para la solución establecida de antemano), se
siguen evaluando puntos en un vecindario cercano a la solución actual,
por medio de introducir un cambio aleatorio en la solución sobre la
que trabajamos, hasta que encontremos una solución que nos de mejores
resultados que la que teníamos hasta el momento. Una vez encontrada
dicha solución más satisfactoria, se descarta la solución antigua
y se empieza a trabajar con la nueva.\\

Este enfoque se consideró interesante durante varios años, ya que
permitía encontrar soluciones razonablemente buenas a problemas de
optimización sencillos, pero que no podían resolverse con técnicas
clásicas de optimización.\\

Estas primeras aproximaciones, aunque todavía eran simples y no
obtenían buenos resultados, llamaron la atención de gran parte de la
comunidad, y empezaron a diseñarse estrategias más sofisticadas para
la resolución de problemas de este tipo. Las premisas de las que se
partían eran las siguientes:

\begin{itemize}
\item Se trataban de resolver problemas complejos, en los que el uso
  de técnicas clásicas quedaba descartado.
\item El espacio de soluciones era amplio, por lo que no podía
  estudiarse por completo.
\item No preocupa tanto la obtención de la solución óptima, si no que
  se adquiere un compromiso entre la bondad de la solución obtenida y
  el tiempo necesario para encontrar dicha solución.
\end{itemize}

A pesar de que estas premisas no fueron consensuadas hasta mediados de
los años ochenta, cuando se acuñó el término \textit{metaheurística}
por Fred W. Glover, las nombramos aquí porque suponen un punto de
partida importante para entender cómo se ha desarrollado esta rama.\\

Volviendo a los primeros pasos que se dieron en el campo, tras los
algoritmos de búsqueda local de principios de los años 60, en el año
1966 aparece el primer conjunto de algoritmos dentro de lo que se
conoce como computación evolutiva. La computación evolutiva es el
conjunto de estrategias que se basan en los principios de la evolución
darwiniana para desarrollar estrategias de resolución de problemas de
optimización. Es sobre este tipo de estrategias sobre las que
incidiremos durante el resto del trabajo. A modo de resumen, la
programación evolutiva, que es este primer conjunto de estrategias de
las que hablamos, fue descrita y desarrollada en un principio por
Lawrence J. Fogel. Aunque los primeros trabajos en los que se aplica
esta técnica son de principios de los 60, hasta el 66 no publicó Fogel
su artículo \textit{Artificial Intelligence Through Simulated
  Evolution}.  Se basa en una población de soluciones que mutan para
generar soluciones nuevas, las cuales entran en competencia con las
antiguas, de forma que sobreviven sólo las mejores soluciones
contempladas.\\

Este enfoque resulta novedoso en el punto en el que ahora no se tiene
una única solución que se modifica para explorar el espacio de
soluciones, si no que se tienen distintas soluciones repartidas, a
priori aleatoriamente, por todo el espacio de búsqueda, evitándose así
uno de los primeros problemas que se detectaron en algoritmos previos,
que era el atasco del algoritmo en óptimos locales, que impedían
encontrar soluciones mejores que se encontrasen a cierta distancia.\\

Dentro de la rama de la computación evolutiva, aparecen en Berlín de
forma prácticamente simultánea (con un par de años de diferencia) lo
que se conocen como estrategias de evolución. Desarrolladas por
Rechenberg y Schwefel, tienen un funcionamiento similar a la
programación evolutiva, aunque con ciertas diferencias que
concretaremos más adelante.\\

Tras estas aproximaciones, aparece en Michigan en el año 1975 el
paradigma más extendido dentro de la computación evolutiva. Se trata
de los algoritmos genéticos, desarrollados y descritos por John H.
Holland. En esta estrategia se introduce el concepto de cruce entre
soluciones, en imitación al apareamiento entre especies animales.\\

En años posteriores, a principios de los 80, aparecen nuevos modelos,
que cambian el enfoque de los años anteriores, y empiezan a buscar
otras inspiraciones en procesos físicos para crear metaheurísticas.
Aparecen así ejemplos como \textit{Simulated annealing}, propuesto por
S. Kirkpatrick en 1983, que mejora el comportamiento de las búsquedas
locales introduciendo una probabilidad de avanzar hacia peores
soluciones, para intentar salir de óptimos locales. Esta probabilidad
va descendiendo a medida que avanza el algoritmo, de forma que al
principio la probabilidad de empeorar la solución es alta, lo que
aumenta la capacidad de exploración del espacio de soluciones del
algoritmo, y al final es pequeña, para intentar refinar todo lo
posible la buena solución encontrada. Este algoritmo imita el proceso
de enfriamiento de los metales fundidos, y la creación de las
estructuras cristalinas que se producen en el proceso. Cuando el metal
está caliente, la probabilidad de que se rompan las conexiones entre
las partículas del metal es más alta, llevando el material a un estado
más inestable (metáfora con el desplazamiento a peores soluciones en
primeras etapas del algoritmo), mientras que cuando se va enfriando,
se van creando más enlaces, para llevar al material a un estado
estable (búsqueda de mejores soluciones al final del algoritmo).\\

A mediados de los 80, concretamente en 1986, aparece otro avance
dentro del campo de las búsquedas locales. Fred W. Glover diseña la
búsqueda tabú, que funciona de la misma forma que las búsquedas
locales, pero permitiendo el avance hacia peores soluciones. Además,
como novedad incorpora una lista de \textit{soluciones tabú}, que son
soluciones evaluadas en las últimas iteraciones del algoritmo. Esta
lista sirve para evitar que el algoritmo retroceda hacia soluciones
anteriormente visitadas, de forma que no se pierdan iteraciones
del mismo sin sentido.\\

Tras estos avances, se intenta ahora hibridar los algoritmos obtenidos
hasta el momento para conseguir soluciones todavía mejores. Aparece
entonces el concepto de algoritmo memético, propuesto por Pablo
Moscato en el Instituto Tecnológico de Calfornia (Caltech) en
1989. Esta metodología trata de unir los algoritmos genéticos con los
algoritmos de búsqueda local. Consiste en ejecutar un algoritmo
genético de los anteriormente explicados, y cada cierto número de
generaciones (nombre con el que se conoce a las iteraciones de un
algoritmo genético) aplicar una búsqueda local sobre ciertos
individuos de la población, con el fin
de mejorar la solución que representan.\\

Tras este desarrollo, empiezan a aparecer algoritmos que se inspiran
en procesos biológicos, que se conocen como algoritmos bioinspirados.
En este sentido, aparece en 1992 el algoritmo de colonia de hormigas,
que simula la organización de un hormiguero, y la cooperación entre
hormigas para encontrar comida. Es ampliamente utilizado actualmente
para la búsqueda de caminos más cortos cuando se han de visitar un
conjunto ciudades (lo que se conoce como problema del viajante de
comercio).\\

Finalmente, ante la gran diversidad de algoritmos que aparecieron para
resolver problemas de optimización, los investigadores en el área
empezaron a preguntarse si existe un único algoritmo que sea capaz de
resolver correctamente cualquier clase de problemas. Durante varios
años se estuvo investigando en este área, hasta que en 1997 se
enunciaron y demostraron (por parte del matemático David Wolpert y el
informático William Macready) los \textit{Non free lunch theorems for
  optimization}. Dichos teoremas sostienen que ``en media, los
resultados obtenidos por dos algoritmos de optimización sobre todas
las clases de problemas posibles son equivalentes''. Esto viene a
decir que, si un algoritmo tiene un mejor comportamiento para una
clase de problemas, se verá perjudicado al intentar resolver problemas
de otro tipo. Esto viene a justificar que se siga investigando en este
área.

\section{Algoritmos genéticos}

\section{Programación evolutiva}

\section{Estrategias de evolución}

\section{Programación genética}

\section{Referencias}

\end{document}


