\documentclass[12pt]{article} \usepackage[utf8x]{inputenc}
\usepackage{graphicx} \usepackage{multirow} \usepackage{hhline}
\usepackage{booktabs} \usepackage{vmargin} %cambia el margen
\usepackage{amsmath,amsthm} \usepackage{amsfonts} \usepackage{float}
\usepackage{listings}


\usepackage[hidelinks]{hyperref}




\title{
  Historia de las Matemáticas\\
  \large Historia de los algoritmos inspirados en la evolución:
  Algoritmos Genéticos, Programación Evolutiva, Estrategias de
  Evolución y Programación Genética.  }


\author{
  Francisco Luque Sánchez \\
  Ignacio Mas Mesa \\
  Miguel Morales Castillo \\
  María del Mar Ruiz Martín \\
}



\begin{document}
\maketitle
\begin{center}  
\includegraphics[scale=0.35]{escudo.png}
\end{center}

\newpage

\tableofcontents % para generar el índice de contenidos

\pagebreak

\section{Introducción}

Las metaheurísticas son una clase de estrategias de resolución de
problemas que aparecieron en los años 50. Este tipo de algoritmos se
inspiran en procesos naturales, físicos o sociales para intentar
resolver problemas, usualmente de optimización, cuando el espacio de
soluciones es demasiado amplio para ser estudiado por métodos
tradicionales.\\

En este trabajo abordaremos, desde una perspectiva histórica, el
origen, evolución y estado actual de este tipo de técnicas, así como
ejemplos prácticos de aplicación. En particular, incidiremos sobre una
clase importante de metaheurísticas, las cuales se inspiran en el
proceso natural de la evolución. Dentro de este grupo se engloban
cuatro enfoques principales, que son los algoritmos genéticos, la
programación evolutiva, la programación genética y las estatregias
de evolución.\\

\section{Metaheurísticas}

Las metaheurísticas aparecieron en los años 50 como respuesta a los
problemas de optimización. Hasta ese momento, los ordenadores habían
sido utilizados como herramientas de ayuda al cálculo, pero no se
habían pensado como máquinas capaces de resolver problemas más
complejos (needs further research). Cuando se intentaron implementar
técnicas de optimización clásica para resolver problemas de búsqueda
(derivación de funciones para el cálculo de extremos locales), se
observó que para muchos problemas este enfoque no era suficiente
(citation needed). Uno de los problemas que surgió fue que las
funciones a optimizar tenían muchos extremos locales, infinitos en
algunos casos. También se encontraron problemas en los que las
funciones a optimizar no eran derivables, por lo que el enfoque
clásico no podía
ser aplicado.\\

Empezaron a aparecer entonces intentos de resolución de problemas de
este tipo con estrategias distintas. El primer ejemplo de este tipo de
estrategias vino en 1951, con un método de aproximación estocástica.
Este método, creado por Herbert Robins y Sutton Monro, trataba de
encontrar extremos de una función utilizando un método de aproximación
por pasos que depende de una variable aleatoria. Así se puede buscar
el mínimo de una función sin tener que buscar la derivada de la misma.\\

Posteriormente, apollándose en los trabajos de Robbins y Monro,
empezaron a aparecer los métodos de búsqueda local. Estos enfoques
consisten en tratar de buscar una solución al problema por medio de
evaluaciones de la función objetivo (función que tratamos de
maximizar). El primer método desarrollado en esta línea fue propuesto
por L. A. Rastrigin, que propuso el algoritmo conocido como
\textit{random search}. Consiste en comenzar evaluando la función
objetivo en un punto aleatorio del espacio de soluciones, y tras esto,
mientras no se haya alcanzado un criterio de parada (se hayan
terminado el número de iteraciones fijadas para el algoritmo, o se
haya alcanzado una cota para la solución establecida de antemano), se
siguen evaluando puntos en un vecindario cercano a la solución actual,
por medio de introducir un cambio aleatorio en la solución sobre la
que trabajamos, hasta que encontremos una solución que nos de mejores
resultados que la que teníamos hasta el momento. Una vez encontrada
dicha solución más satisfactoria, se descarta la solución antigua
y se empieza a trabajar con la nueva.\\

Este enfoque se consideró interesante durante varios años, ya que
permitía encontrar soluciones razonablemente buenas a problemas de
optimización sencillos, pero que no podían resolverse con técnicas
clásicas de optimización.\\

Estas primeras aproximaciones, aunque todavía eran simples y no
obtenían buenos resultados, llamaron la atención de gran parte de la
comunidad, y empezaron a diseñarse estrategias más sofisticadas para
la resolución de problemas de este tipo. Las premisas de las que se
partían eran las siguientes:

\begin{itemize}
\item Se trataban de resolver problemas complejos, en los que el uso
  de técnicas clásicas quedaba descartado.
\item El espacio de soluciones era amplio, por lo que no podía
  estudiarse por completo.
\item No preocupa tanto la obtención de la solución óptima, si no que
  se adquiere un compromiso entre la bondad de la solución obtenida y
  el tiempo necesario para encontrar dicha solución.
\end{itemize}

A pesar de que estas premisas no fueron consensuadas hasta mediados de
los años ochenta, cuando se acuñó el término \textit{metaheurística}
por Fred W. Glover, las nombramos aquí porque suponen un punto de
partida importante para entender cómo se ha desarrollado esta rama.\\

Volviendo a los primeros pasos que se dieron en el campo, tras los
algoritmos de búsqueda local de principios de los años 60, en el año
1966 aparece el primer conjunto de algoritmos dentro de lo que se
conoce como computación evolutiva. La computación evolutiva es el
conjunto de estrategias que se basan en los principios de la evolución
darwiniana para desarrollar estrategias de resolución de problemas de
optimización. Es sobre este tipo de estrategias sobre las que
incidiremos durante el resto del trabajo. A modo de resumen, la
programación evolutiva, que es este primer conjunto de estrategias de
las que hablamos, fue descrita y desarrollada en un principio por
Lawrence J. Fogel. Aunque los primeros trabajos en los que se aplica
esta técnica son de principios de los 60, hasta el 66 no publicó Fogel
su artículo \textit{Artificial Intelligence Through Simulated
  Evolution}.  Se basa en una población de soluciones que mutan para
generar soluciones nuevas, las cuales entran en competencia con las
antiguas, de forma que sobreviven sólo las mejores soluciones
contempladas.\\

Este enfoque resulta novedoso en el punto en el que ahora no se tiene
una única solución que se modifica para explorar el espacio de
soluciones, si no que se tienen distintas soluciones repartidas, a
priori aleatoriamente, por todo el espacio de búsqueda, evitándose así
uno de los primeros problemas que se detectaron en algoritmos previos,
que era el atasco del algoritmo en óptimos locales, que impedían
encontrar soluciones mejores que se encontrasen a cierta distancia.\\

Dentro de la rama de la computación evolutiva, aparecen en Berlín de
forma prácticamente simultánea (con un par de años de diferencia) lo
que se conocen como estrategias de evolución. Desarrolladas por
Rechenberg y Schwefel, tienen un funcionamiento similar a la
programación evolutiva, aunque con ciertas diferencias que
concretaremos más adelante.\\

Tras estas aproximaciones, aparece en Michigan en el año 1975 el
paradigma más extendido dentro de la computación evolutiva. Se trata
de los algoritmos genéticos, desarrollados y descritos por John H.
Holland. En esta estrategia se introduce el concepto de cruce entre
soluciones, en imitación al apareamiento entre especies animales.\\

En años posteriores, a principios de los 80, aparecen nuevos modelos,
que cambian el enfoque de los años anteriores, y empiezan a buscar
otras inspiraciones en procesos físicos para crear metaheurísticas.
Aparecen así ejemplos como \textit{Simulated annealing}, propuesto por
S. Kirkpatrick en 1983, que mejora el comportamiento de las búsquedas
locales introduciendo una probabilidad de avanzar hacia peores
soluciones, para intentar salir de óptimos locales. Esta probabilidad
va descendiendo a medida que avanza el algoritmo, de forma que al
principio la probabilidad de empeorar la solución es alta, lo que
aumenta la capacidad de exploración del espacio de soluciones del
algoritmo, y al final es pequeña, para intentar refinar todo lo
posible la buena solución encontrada. Este algoritmo imita el proceso
de enfriamiento de los metales fundidos, y la creación de las
estructuras cristalinas que se producen en el proceso. Cuando el metal
está caliente, la probabilidad de que se rompan las conexiones entre
las partículas del metal es más alta, llevando el material a un estado
más inestable (metáfora con el desplazamiento a peores soluciones en
primeras etapas del algoritmo), mientras que cuando se va enfriando,
se van creando más enlaces, para llevar al material a un estado
estable (búsqueda de mejores soluciones al final del algoritmo).\\

A mediados de los 80, concretamente en 1986, aparece otro avance
dentro del campo de las búsquedas locales. Fred W. Glover diseña la
búsqueda tabú, que funciona de la misma forma que las búsquedas
locales, pero permitiendo el avance hacia peores soluciones. Además,
como novedad incorpora una lista de \textit{soluciones tabú}, que son
soluciones evaluadas en las últimas iteraciones del algoritmo. Esta
lista sirve para evitar que el algoritmo retroceda hacia soluciones
anteriormente visitadas, de forma que no se pierdan iteraciones
del mismo sin sentido.\\

Tras estos avances, se intenta ahora hibridar los algoritmos obtenidos
hasta el momento para conseguir soluciones todavía mejores. Aparece
entonces el concepto de algoritmo memético, propuesto por Pablo
Moscato en el Instituto Tecnológico de Calfornia (Caltech) en
1989. Esta metodología trata de unir los algoritmos genéticos con los
algoritmos de búsqueda local. Consiste en ejecutar un algoritmo
genético de los anteriormente explicados, y cada cierto número de
generaciones (nombre con el que se conoce a las iteraciones de un
algoritmo genético) aplicar una búsqueda local sobre ciertos
individuos de la población, con el fin
de mejorar la solución que representan.\\

Tras este desarrollo, empiezan a aparecer algoritmos que se inspiran
en procesos biológicos, que se conocen como algoritmos bioinspirados.
En este sentido, aparece en 1992 el algoritmo de colonia de hormigas,
que simula la organización de un hormiguero, y la cooperación entre
hormigas para encontrar comida. Es ampliamente utilizado actualmente
para la búsqueda de caminos más cortos cuando se han de visitar un
conjunto ciudades (lo que se conoce como problema del viajante de
comercio).\\

Finalmente, ante la gran diversidad de algoritmos que aparecieron para
resolver problemas de optimización, los investigadores en el área
empezaron a preguntarse si existe un único algoritmo que sea capaz de
resolver correctamente cualquier clase de problemas. Durante varios
años se estuvo investigando en este área, hasta que en 1997 se
enunciaron y demostraron (por parte del matemático David Wolpert y el
informático William Macready) los \textit{Non free lunch theorems for
  optimization}. Dichos teoremas sostienen que ``en media, los
resultados obtenidos por dos algoritmos de optimización sobre todas
las clases de problemas posibles son equivalentes''. Esto viene a
decir que, si un algoritmo tiene un mejor comportamiento para una
clase de problemas, se verá perjudicado al intentar resolver problemas
de otro tipo. Esto viene a justificar que se siga investigando en este
área.

\section{Algoritmos genéticos}

\section{Programación evolutiva}

\section{Estrategias de evolución}

\section{Programación genética}


\subsection{Introducción histórica} 

La programación genética es un caso particular de algoritmos genéticos usados para mejorar programas de ordenador de un modo automático. La población la componen programas de  ordenador (individuos) que se cruzan unos con otros, y al igual que ocurre con los algoritmos genéticos y con el paso del tiempo, los mejores individuos sobreviven y eventualmente evolucionan para mejorar. \\

La primera referencia que se tiene de evolucionar programas es probablemente la de Alan Turing en la década de los 50. Sin embargo, pasaron 30 años hasta que Richard Forsyth demostrara el exito en la evolución de pequeños programas, representados como arboles, para mejorar la clasificación de las pruebas de una escena de crimen.\\

En 1988 John Koza, estudiante de John Holland, patentó un algoritmo genético orientado a la evolución de programas, seguido de una publicación en la International Joint Conference on Artificial Inteligence. Koza ha sido el exponente principal de la programación genética aplicando esta a complejos problemas de búsqueda.
En la década de 1990, la programación genética se aplicó principalmente para resolver problemas sencillos debido a su alto coste computacional.\\

Recientemente la programación genética ha cobrado protagonismo debido a los resultados positivos que ha mostrado en áreas como la computación cuántica, ordenamiento y búsqueda gracias a la potencia de computo de la que disponemos actualmente. Una de las grandes metas de la ciencia de la computación es, dado un problema, que la máquina sea capaz de construir un programa capaz de resolverlo, y la programación genética muestra suficiente potencial para conseguirlo en un futuro.\\


\subsection {Creación de la población}

Cada individuo se representa mediante una estructura de árbol, donde los nodos no terminales representan funciones cuyos hijos son los parámetros que necesita la función como argumento, esto supone un cambio respecto a los algoritmos genéticos donde los individuos se representan mediante estructuras lineales como valores reales o cadenas de bits.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\textwidth]{individuo.PNG}
    \caption{Individuo que representa la función \(3\times(x+6)\).}
    \label{fig:dfd:1}
\end{figure}

La elección de los genes disponibles es una tarea importante ya que una mala selección podria causar que no evolucione la solución.\\

Una vez que los genes han sido seleccionados, se genera una poblacion de individuos de forma aleatoria y sin repetición como ocurre con los algoritmos genéticos. Koza desarrollo tres técnicas para ello: grow,full y ramped-half-and-half.

\subsubsection{Grow}

La población es creada eligiendo una profundidad máxima \(m\), con esta técnica se crea un individuo nuevo cada vez con una profundidad no mayor a \(m\), el proceso se realiza de la siguiente forma:
\begin{itemize}
\item  Desde la raiz , cada nodo se elige como función o terminal de forma aleatoria.
\item  Si el nodo es terminal, se le asigna un nodo terminal de forma aleatoria
\item  Si el nodo es una función, se le asigna una función de forma aleatoria y a ese nodo se le añaden tantos hijos como parámetros tenga la función elegida. Para cada hijo se repite el mismo proceso, a no ser que ya tenga profundidad \(m\), en ese caso para el hijo se selecciona un terminal aleatorio.
\end{itemize}

Esta estrategia genera individuos de profundidad variable no mayor que \(m\) pero proporciona un rango de variedad muy amplio en la población.

\subsubsection{Full}

Esta estrategia, a diferencia de grow, garantiza que todos los individuos tienen la misma profundidad, aunque el número de nodos es variable. Aqui también se necesita especificar una profundidad \(m\), y el proceso es el siguiente:

 Partiendo de la raiz, cada nodo con una profundidad menor que \(m\) , se convierte en una función aleatoria. Si el nodo tiene profundidad \(m\) entonces se convierte en un terminal aleatorio. 
 Todas las funciones tienen un numero de hijos igual a la cantidad de parámetros que necesitan como argumento. Con esta estrategia te aseguras que todos los individuos tienen una profundidad \(m\) aunque por contra la variación es menor que con la estrategia grow.\\
 
 \subsubsection{Ramped-half-and-half}
 
 Se propone esta estrategia para aumentar la variación usando las dos estrategias anteriores. Solo se especifica una profundidad máxima, y se generan la mitad de los individuos usando el método grow, mientras que la otra mitad se genera usando el método full, creando asi una población con una gran diversidad.
 
 \subsection{Función Fitness}
 
 Al igual que ocurre en los algoritmos genéticos, una vez que la población esta inicializada, los individuos necesitan ser evaluados para saber lo bueno o malo que es un individuo. La función fitness mas común es aquella que se adapte de forma más natural al problema que se plantee. Un ejemplo sería  el problema de clasificación donde la función fitness mas natural seria el número de aciertos.
 
 \subsection{Operadores}
 
 Análogamente a los algoritmos genéticos, la programación genética cuenta con operadores de selección, cruce y mutación.Actualmente se consideran otras operaciones como la edición, permutación o el encapsulamiento , aunque la mayoria de ellas fueron ignoradas por Koza en sus primeros trabajos.
 
 \subsubsection{Selección}
 
 Para la selección se utilizan los mecanismos habituales de los algoritmos genéticos, en el caso de la programación genética, Koza permitía que un 10\% de la poblacón se pudiese reproducir además del proceso de selección habitual. La función de selección es la encargada de elegir que individuo se reproduce, cuya reproducción no es mas que elegir a ese individuo e introducir una copia de el mismo en la población, si la función fitness es fija, la reproducción tiene un efecto significativo en el tiempo ya que un individuo generado por reproducción tendrá el mismo valor fitness que su padre.
 
 \subsubsection{Cruce}
 
 El proceso del operador de cruce es similar al de los algoritmos genéticos, en este caso generamos aleatoriamente una arista a cada padre y se intercambian los subárboles generando así dos hijos nuevos.\\
 Algunas consideraciones a tener en cuenta pueden ser la de no efectuar el cruce si la profundidad del árbol supera el máximo para evitar que crezca indefinidamente. Otra consideración posible sería la de incorporar criterios que penalicen en la función fitness una excesiva complejidad de los programas.
 
 \subsubsection{Mutación}
 
 La mutación en el caso de la programación genética se puede realizar de dos formas:
 
 \begin{itemize}
\item  Mutación de subárbol: en esta mutación se escoge una arista y se sustituye el subárbol conectado a esta por otro generado aleatoriamente, sin superar el tamaño máximo establecido.
\item  Mutación de punto: se escoge un nodo de forma aleatoria y se cambia su valor por otro del mismo tipo, esto se realiza haciendo previamente una lista de los terminales y funciones que pueden intercambiarse entre si para que sigan siendo individuos válidos.
\end{itemize}

La mutación aqui tiene menos importancia que en los algoritmos genéticos ya que el operador de cruce es suficiente para mantener la diversidad.

\subsection{Finalización}

Como conclusión a esta sección añadir que el reemplazo se realiza sustituyendo la población nueva por la anterior, y el proceso se repite hasta cumplir el criterio de parada al igual que ocurre en los algoritmos genéticos, el programa elegido será el mejor de la población final. El siguiente diagrama de flujo resume todo lo explicado en la sección.
  
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{FlowchartGP.PNG}
    \caption{Diagrama de flujo de la Programación genética.}
    \label{fig:dfd:1}
\end{figure}


\section{Referencias}
%https://www.cs.montana.edu/~bwall/cs580/introduction_to_gp.pdf
%http://geneticprogramming.com/history/
%https://es.wikipedia.org/wiki/Programaci%C3%B3n_gen%C3%A9tica
%http://sci2s.ugr.es/sites/default/files/files/Teaching/GraduatesCourses/Bioinformatica/Tema%2013%20-%20PG.pdf
%Koza, John R. 1992. Genetic Programming: On the Programming of Computers by Means of Natural Selection. Cambridge, MA: The MIT Press.

\end{document}


