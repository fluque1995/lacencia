\documentclass[12pt]{article} \usepackage[utf8x]{inputenc}
\usepackage{graphicx} \usepackage{multirow} \usepackage{hhline}
\usepackage{booktabs} \usepackage{vmargin} %cambia el margen
\usepackage{amsmath,amsthm} \usepackage{amsfonts} \usepackage{float}
\usepackage{listings}


\usepackage[hidelinks]{hyperref}




\title{
  Historia de las Matemáticas\\
  \large Historia de los algoritmos inspirados en la evolución:
  Algoritmos Genéticos, Programación Evolutiva, Estrategias de
  Evolución y Programación Genética.  }


\author{
  Francisco Luque Sánchez \\
  Ignacio Mas Mesa \\
  Miguel Morales Castillo \\
  María del Mar Ruiz Martín \\
}



\begin{document}
\maketitle
\begin{center}  
  \includegraphics[scale=0.35]{escudo.png}
\end{center}

\newpage

\tableofcontents % para generar el índice de contenidos

\pagebreak

\section{Introducción}

Las metaheurísticas son una clase de estrategias de resolución de
problemas que aparecieron en los años 50. Este tipo de algoritmos se
inspiran en procesos naturales, físicos o sociales para intentar
resolver problemas, usualmente de optimización, cuando el espacio de
soluciones es demasiado amplio para ser estudiado por métodos
tradicionales.\\

En este trabajo abordaremos, desde una perspectiva histórica, el
origen, evolución y estado actual de este tipo de técnicas, así como
ejemplos prácticos de aplicación. En particular, incidiremos sobre una
clase importante de metaheurísticas, las cuales se inspiran en el
proceso natural de la evolución. Dentro de este grupo se engloban
cuatro enfoques principales, que son los algoritmos genéticos, la
programación evolutiva, la programación genética y las estatregias
de evolución.\\

\section{Metaheurísticas}

Las metaheurísticas aparecieron en los años 50 como respuesta a los
problemas de optimización. Hasta ese momento, los ordenadores habían
sido utilizados como herramientas de ayuda al cálculo, pero no se
habían pensado como máquinas capaces de resolver problemas más
complejos (needs further research). Cuando se intentaron implementar
técnicas de optimización clásica para resolver problemas de búsqueda
(derivación de funciones para el cálculo de extremos locales), se
observó que para muchos problemas este enfoque no era suficiente
(citation needed). Uno de los problemas que surgió fue que las
funciones a optimizar tenían muchos extremos locales, infinitos en
algunos casos. También se encontraron problemas en los que las
funciones a optimizar no eran derivables, por lo que el enfoque
clásico no podía
ser aplicado.\\

Empezaron a aparecer entonces intentos de resolución de problemas de
este tipo con estrategias distintas. El primer ejemplo de este tipo de
estrategias vino en 1951, con un método de aproximación estocástica.
Este método, creado por Herbert Robins y Sutton Monro, trataba de
encontrar extremos de una función utilizando un método de aproximación
por pasos que depende de una variable aleatoria. Así se puede buscar
el mínimo de una función sin tener que buscar la derivada de la misma.\\

Posteriormente, apoyándose en los trabajos de Robbins y Monro,
empezaron a aparecer los métodos de búsqueda local. Estos enfoques
consisten en tratar de buscar una solución al problema por medio de
evaluaciones de la función objetivo (función que tratamos de
maximizar). El primer método desarrollado en esta línea fue propuesto
por L. A. Rastrigin, que propuso el algoritmo conocido como
\textit{random search}. Consiste en comenzar evaluando la función
objetivo en un punto aleatorio del espacio de soluciones, y tras esto,
mientras no se haya alcanzado un criterio de parada (se hayan
terminado el número de iteraciones fijadas para el algoritmo, o se
haya alcanzado una cota para la solución establecida de antemano), se
siguen evaluando puntos en un vecindario cercano a la solución actual,
por medio de introducir un cambio aleatorio en la solución sobre la
que trabajamos, hasta que encontremos una solución que nos dé mejores
resultados que la que teníamos hasta el momento. Una vez encontrada
dicha solución más satisfactoria, se descarta la solución antigua
y se empieza a trabajar con la nueva.\\

Este enfoque se consideró interesante durante varios años, ya que
permitía encontrar soluciones razonablemente buenas a problemas de
optimización sencillos, pero que no podían resolverse con técnicas
clásicas de optimización.\\

Estas primeras aproximaciones, aunque todavía eran simples y no
obtenían buenos resultados, llamaron la atención de gran parte de la
comunidad, y empezaron a diseñarse estrategias más sofisticadas para
la resolución de problemas de este tipo. Las premisas de las que se
partían eran las siguientes:

\begin{itemize}
\item Se trataban de resolver problemas complejos, en los que el uso
  de técnicas clásicas quedaba descartado.
\item El espacio de soluciones era amplio, por lo que no podía
  estudiarse por completo.
\item No preocupa tanto la obtención de la solución óptima, si no que
  se adquiere un compromiso entre la bondad de la solución obtenida y
  el tiempo necesario para encontrar dicha solución.
\end{itemize}

A pesar de que estas premisas no fueron consensuadas hasta mediados de
los años ochenta, cuando se acuñó el término \textit{metaheurística}
por Fred W. Glover, las nombramos aquí porque suponen un punto de
partida importante para entender cómo se ha desarrollado esta rama.\\

Volviendo a los primeros pasos que se dieron en el campo, tras los
algoritmos de búsqueda local de principios de los años 60, en el año
1966 aparece el primer conjunto de algoritmos dentro de lo que se
conoce como computación evolutiva. La computación evolutiva es el
conjunto de estrategias que se basan en los principios de la evolución
darwiniana para desarrollar estrategias de resolución de problemas de
optimización. Es sobre este tipo de estrategias sobre las que
incidiremos durante el resto del trabajo. A modo de resumen, la
programación evolutiva, que es este primer conjunto de estrategias de
las que hablamos, fue descrita y desarrollada en un principio por
Lawrence J. Fogel. Aunque los primeros trabajos en los que se aplica
esta técnica son de principios de los 60, hasta el 66 no publicó Fogel
su artículo \textit{Artificial Intelligence Through Simulated
  Evolution}.  Se basa en una población de soluciones que mutan para
generar soluciones nuevas, las cuales entran en competencia con las
antiguas, de forma que sobreviven sólo las mejores soluciones
contempladas.\\

Este enfoque resulta novedoso en el punto en el que ahora no se tiene
una única solución que se modifica para explorar el espacio de
soluciones, si no que se tienen distintas soluciones repartidas, a
priori aleatoriamente, por todo el espacio de búsqueda, evitándose así
uno de los primeros problemas que se detectaron en algoritmos previos,
que era el atasco del algoritmo en óptimos locales, que impedían
encontrar soluciones mejores que se encontrasen a cierta distancia.\\

Dentro de la rama de la computación evolutiva, aparecen en Berlín de
forma prácticamente simultánea (con un par de años de diferencia) lo
que se conocen como estrategias de evolución. Desarrolladas por
Rechenberg y Schwefel, tienen un funcionamiento similar a la
programación evolutiva, aunque con ciertas diferencias que
concretaremos más adelante.\\

Tras estas aproximaciones, aparece en Míchigan en el año 1975 el
paradigma más extendido dentro de la computación evolutiva. Se trata
de los algoritmos genéticos, desarrollados y descritos por John H.
Holland. En esta estrategia se introduce el concepto de cruce entre
soluciones, en imitación al apareamiento entre especies animales.\\

En años posteriores, a principios de los 80, aparecen nuevos modelos,
que cambian el enfoque de los años anteriores, y empiezan a buscar
otras inspiraciones en procesos físicos para crear metaheurísticas.
Aparecen así ejemplos como \textit{Simulated annealing}, propuesto por
S. Kirkpatrick en 1983, que mejora el comportamiento de las búsquedas
locales introduciendo una probabilidad de avanzar hacia peores
soluciones, para intentar salir de óptimos locales. Esta probabilidad
va descendiendo a medida que avanza el algoritmo, de forma que al
principio la probabilidad de empeorar la solución es alta, lo que
aumenta la capacidad de exploración del espacio de soluciones del
algoritmo, y al final es pequeña, para intentar refinar todo lo
posible la buena solución encontrada. Este algoritmo imita el proceso
de enfriamiento de los metales fundidos, y la creación de las
estructuras cristalinas que se producen en el proceso. Cuando el metal
está caliente, la probabilidad de que se rompan las conexiones entre
las partículas del metal es más alta, llevando el material a un estado
más inestable (metáfora con el desplazamiento a peores soluciones en
primeras etapas del algoritmo), mientras que cuando se va enfriando,
se van creando más enlaces, para llevar al material a un estado
estable (búsqueda de mejores soluciones al final del algoritmo).\\

A mediados de los 80, concretamente en 1986, aparece otro avance
dentro del campo de las búsquedas locales. Fred W. Glover diseña la
búsqueda tabú, que funciona de la misma forma que las búsquedas
locales, pero permitiendo el avance hacia peores soluciones. Además,
como novedad incorpora una lista de \textit{soluciones tabú}, que son
soluciones evaluadas en las últimas iteraciones del algoritmo. Esta
lista sirve para evitar que el algoritmo retroceda hacia soluciones
anteriormente visitadas, de forma que no se pierdan iteraciones
del mismo sin sentido.\\

Tras estos avances, se intenta ahora hibridar los algoritmos obtenidos
hasta el momento para conseguir soluciones todavía mejores. Aparece
entonces el concepto de algoritmo memético, propuesto por Pablo
Moscato en el Instituto Tecnológico de Calfornia (Caltech) en
1989. Esta metodología trata de unir los algoritmos genéticos con los
algoritmos de búsqueda local. Consiste en ejecutar un algoritmo
genético de los anteriormente explicados, y cada cierto número de
generaciones (nombre con el que se conoce a las iteraciones de un
algoritmo genético) aplicar una búsqueda local sobre ciertos
individuos de la población, con el fin
de mejorar la solución que representan.\\

Tras este desarrollo, empiezan a aparecer algoritmos que se inspiran
en procesos biológicos, que se conocen como algoritmos bioinspirados.
En este sentido, aparece en 1992 el algoritmo de colonia de hormigas,
que simula la organización de un hormiguero, y la cooperación entre
hormigas para encontrar comida. Es ampliamente utilizado actualmente
para la búsqueda de caminos más cortos cuando se han de visitar un
conjunto ciudades (lo que se conoce como problema del viajante de
comercio).\\

Finalmente, ante la gran diversidad de algoritmos que aparecieron para
resolver problemas de optimización, los investigadores en el área
empezaron a preguntarse si existe un único algoritmo que sea capaz de
resolver correctamente cualquier clase de problemas. Durante varios
años se estuvo investigando en este área, hasta que en 1997 se
enunciaron y demostraron (por parte del matemático David Wolpert y el
informático William Macready) los \textit{Non free lunch theorems for
  optimization}. Dichos teoremas sostienen que ``en media, los
resultados obtenidos por dos algoritmos de optimización sobre todas
las clases de problemas posibles son equivalentes''. Esto viene a
decir que, si un algoritmo tiene un mejor comportamiento para una
clase de problemas, se verá perjudicado al intentar resolver problemas
de otro tipo. Esto viene a justificar que se siga investigando en este
área.

\section{Algoritmos genéticos}

Los algoritmos genéticos pertenecen a la amplia familia de los
algoritmos evolutivos.  Sin embargo, a diferencia de la mayoría de
algoritmos evolutivos, que surgen con la finalidad de resolver
problemas de simulación para ingeniería y biología o para problemas de
optimización, su origen es sustancialmente diferente. A principios de
los años 60, John Henry Holland, profesor de psicología, ingeniería
eléctrica y ciencias de la computación en la universidad de Míchigan,
comienza a desarrollar lo que él llama los algoritmos
genéticos. Holland propone estos algoritmos en su búsqueda por
comprender la evolución de una población, y de forma más general, de
encontrar los criterios seguidos por los sistemas adaptativos. Publica
así en 1962 un estudio sobre el tema, estudio que
se considerará el nacimiento de los algoritmos genéticos.\\

Holland inicialmente propone un sistema adaptativo formado por una
población de cromosomas que irán evolucionando de forma que las
futuras generaciones tiendan a ser mejores. Para ello, contará con
cromosomas, que serán cadenas binarias, donde cada uno de sus
elementos será llamado gen. A partir de una población inicial, los
cromosomas interactuarán de forma iterativa dando lugar a nuevas
generaciones. El proceso iterativo contará con las siguientes fases:
en primer lugar se realiza una selección de individuos en nuestra
población para reproducirse. A continuación se aplica un operador de
cruce entre los padres, de forma que se obtengan descendientes
similares a ambos. Se pasa a aplicar una serie de modificaciones
aleatorias a algunos, o a todos, los descendientes obtenidos. En un
proceso conocido como mutación. A continuación se aplicará el operador
de inversión, que consiste en tomar una subcadena del cromosoma y
sustituirla por su inversa. Finalmente se somete a la población
anterior, junto a la descendencia obtenida a un proceso de selección,
en el que se seleccionarán los mejores individuos según una función
fitness, y éstos pasarán
a formar la nueva generación.\\

Holland entendía esta función fitness como una medida de la capacidad
de competición e innovación de los individuos para dinámicamente
responder ante cambios no predecibles del ambiente. Con esta
formulación de los algoritmos genéticos, Holland fue el primero en
introducir explícitamente las nociones de cruce, o cualquier otro tipo
de operadores de recombinación
en el ámbito de los algoritmos evolutivos.\\

En los próximos años, surgen figuras como Bagley, cuya tésis trata
sobre la aplicación de los algoritmos genéticos sobre la función de
evaluación en programas que juegan a juegos, o la tésis de Cavicchio
(1970) en la que trata los algoritmos genéticos desde una perspectiva
de búsqueda adaptativa.  Introduce además el concepto de elitismo, con
el que cada generación mantendrá la mejor solución obtenida hasta el
momento, y operadores de mutación que se
adaptan a lo largo de las iteraciones según las necesidades de cada generación.\\

A pesar de las figuras anteriores y algunas más, durante los años
sesenta el principal desarrollo y estudio de los algoritmos genéticos
se centra en la universidad de Míchigan, con John Holland y sus
estudiantes. Será durante estos años cuando Holland, junto con algunos
alumnos de doctorado desarrollará una
función fitness con la que predecir la calidad de cada generación.\\

En 1972 destaca la tésis de Frantz, en la que propone nuevas técnicas
de cruce,
con lo que se conoce como operadores de cruce multipuntos.\\



En 1975 se produce el evento más importante de la historia de los
algoritmos genéticos cuando John Holland publica su libro ``Adaptation
in Natural and Artificial Systems'' en el que establece la estructura
de los algoritmos genéticos y presenta un estudio matemático de los
fundamentos teóricos de los mismos. Esto último supone un gran avance
en el campo de los algoritmos evolutivos, puesto que es la primera vez
que se estudia teóricamente el
comportamiento de algún algoritmo evolutivo.\\


En su libro John Holland mantiene la estructura original que propuso
en 1962, pero añade la noción de ``esquemas''. Un esquema será
simplemente un patrón presente en la estructura de los cromosomas. A
partir de los esquemas Holland establecía una medida de bondad de la
generación actual a partir de los valores fitness obtenidos para cada
esquema, donde entendía el valor fiteness de un esquema como la media
de los valores obtenidos por cada cromosoma de la población que
cumpliese el esquema en cuestión. Con esta medida se pretendía guiar
el proceso
de evolución de la población. \\

A partir de lo anterior introdujo una formalización para predecir la
calidad de la siguiente generación a partir de lo que se conoció como
el Teorema de los
esquemas de Holland.\\


También en 1975, Kenneth De Jong, estudiante de doctorado de Holland,
presenta su tésis doctoral, que será el primer estudio del uso de
algoritmos genéticos para resolver problemas de optimización. Con el
trabajo de Kenneth se pone de manifiesto al utilidad práctica de los
algoritmos genéticos. Además establece un standard a seguir con los
mismos, y durante años cualquier estudio de calidad sobre algoritmos
genéticos seguía las pautas marcadas por Kenneth y presentaba
los benchmarks presentes en su tésis.\\

En dicha tésis, De Jong no solo estudia teóricamente el comportamiento
de los algoritmos genéticos, sino que también los estudia desde un
punto de vista experimental. Además, pone de manifiesto el potencial
que presentan los algoritmos genéticos para resolver problemas de
optimización desde un punto de vista teórico,
potencial que ya había sugerido anteriormente Sampson.\\

Tras estas dos principales publicaciones, aumentan en los años 70 y 80
las investigaciones sobre los algoritmos genéticos. Poco a poco los
algoritmos genéticos van cogiendo fuerza en el terreno científico y
surge una comunidad de estudios de los mismos.  Aumenta también la
aplicación de los mismos, que empiezan a aplicarse en campos de
ingeniería y optimización sobre funciones con domino en los enteros.\\

A mediados de los 70 en otras universidades comienzan a estudiar los
algoritmos genéticos, y comienzan a aparecer múltiples tésis
doctorales sobre los mismos, de las que se podrían destacar las de
Bethke, Booker, y Goldberg. Sin embargo, el desarrollo de los
algoritrmos genéticos continúa siendo muy lento, ya que la comunidad
de la Inteligencia Artificial aún era excéptica ante los mismos y se
centra en el desarrollo de otras técnicas novedosas
y de gran funcionalidad como el nacimiento del perceptrón.\\

En el verano de 1976, investigadores de diversas universidades, entre
ellas las de Michigan, Pitsburg o Alberta, organizaron una conferencia
sobre sistemas adaptativos en Ann Arbor, Míchigan. Apenas participaron
20 investigadores, pero supuso la puesta en contacto de diversos
científicos que trabajaban en el área de los algoritmos
genéticos. Durante los siguientes años siguieron repitiendo el
evento. Y en 1981 Holland, De Jong y Sampson fundan ``An
Interdisciplinary Workshop in Adaptive Systems'' en la universida de Míchigan.\\


Hasta los años 80 el desarrollo de los algoritmos genéticos había
seguido un enfoque muy teórico, pero el aumento del interés de la
comunidad científica en los mismos desemboca en que a mediados de los
años 80 se organice
en Pittsburgh, Pensilvania, la Primera Conferencia Internacional de Algoritmos Genéticos.\\

En esta conferencia, con 75 participantes, se discutieron temas tanto
teóricos como prácticos de los algoritmos genéticos. El éxito de la
conferencia fue tal que acordaron repetirla con
carácter bianual.\\

A partir de estas conferencias comienzan a surgir numerosos libros
sobre el tema. Cabe destacar el publicado por Golsberg (1987), puesto
que presenta una visión clara y precisa de los algoritmos genéticos en
un tono sencillo, fácil de entender para cualquier persona aunque no
fuera experta en el tema. Esto supone una amplia
difusión de los algoritmos genéticos.\\

El gran crecimiento de la comunidad desembocó en la creación de la
Sociedad Internacional de Algoritmos Genéticos (ISGA) en 1989. A
partir de entonces el desarrollo de los algoritmos genéticos ha
presenta un crecimiento rápido y desordenado, sin seguir ningún
estándar, y utilizados también para optimizar problemas de naturaleza
real. En consecuencia, los 90 fueron un periodo de tremendo
crecimiento y diversidad del área de los algoritmos genéticos. \\


Conforme surgen nuevos estudios de los algoritmos genéticos, se
comprueba que las características que Holland establecía en su libro
``Adaptation in Natural and Artificial Systems'' como deseables en un
algoritmo genético, no concuerdan con los experimentos obtenidos. Esto
se debe principalmente a que, por la reducida capacidad de cálculo que
se tenía, los experimentos realizados por Holland previos a sus
conclusiones habían sido con muestras muy pequeñas y tamaños de
poblaciones demasiado
pequeñas, dando lugar a que los resultados no fuesen fiables. \\

Sin embargo, a pesar de la mala predicción de las características
estimadas por Holland de un algoritmo genético, el uso de los esquemas
como fundamento teórico del buen funcionamiento de los
algorítmos genéticos ha sido ampliamente aceptado hasta hace poco.\\


Lo cierto es que, más allá de la descripción dada en ``Adaptation in
Natural and Artificial Systems'' no existe una definición rigurosa de
qué es un algoritmo genético que sea aceptada por la comunidad de los
algoritmos evolutivos, y muchas veces la frontera entre estos
algoritmos y otros evolutivos es
realmente débil. \\

Sin embargo, la mayoría de los algoritmos hoy catalogados como
algoritmos genéticos coinciden en los siguiente elementos: se cuenta
con una población de cromosomas, que a partir de una función fitness
que se pretende optimizar son sometidos a los operadores de selección,
cruce, mutación y reemplazamiento de forma iterativa buscando
optimizar el valor de dicha función fitness.  Podemos notar que el
operador de inversión introducido por Holland ha desaparecido del
panorama actual, ya que recibió duras críticas debido a que sus
ventajas, en caso de existir, no han
sido establecidas o explicadas.\\


\section{Programación evolutiva}

Uno de los primeros enfoques que se tomaron dentro del ámbito de la
computación evolutiva fue el de la programación evolutiva. Fue
propuesto por Lawrence J. Fogel, un estudiante de la Universidad de
Nueva York y doctorado por la Universidad de California. Comenzó
trabajando como ingeniero aeroespacial en \textit{General Dynamics}
tras terminar la carrera en ingeniería eléctrica. Tras esto, sirvió
como asistente del Director Asociado en la \textit{National Science
  Foundation}, donde estuvo trabajando en modelos matemáticos para
predecir el impacto económico que tendría la inversión en
investigación científica.  Dichos estudios fueron aplicados en varias
agencias gubernamentales, como el Departamento de Defensa, la
Administración Nacional Espacial y Aeronáutica, el Departamento de
Salud, o la Administración Educativa. Este trabajo multidisciplinar
motivó el interés de Fogel en diversas áreas como la cibernética o la
biotecnología, y lo llevó a la hipótesis de que la simulación de la
evolución en un ordenador podía ser utilizada para generar
inteligencia artificial.\\

Todos estos razonamientos fueron puestos en práctica tras su vuelta a
\textit{General Dynamic}, donde comenzó a explorar la programación
evolutiva en la predicción de series temporales. Tras estos trabajos,
publicó su tesis en la Universidad de California, como hemos
mencionado antes, en la que comenzó a hablar del término programación
evolutiva y su utilidad para la resolución de problemas de
optimización y búsqueda. Dicha tesis tuvo lugar en el año 1964, y es
la fecha en la que se considera que se especificó y desarolló la
técnica.\\

Tras esto, en 1965, abandonó su puesto en \textit{General Dynamics}
para fundar su propia empresa, \textit{Decision Science, Inc.}, que
estaba enfocada a la aplicación de la programación evolutiva para la
resolución de problemas reales, específicamente en las áreas de
simulación por ordenador, predicción y control de sistemas. Dicha
empresa fue pionera en ser ideada específicamente para aplicar la
computación evolutica para resolver problemas reales, y no como mera
investigación dentro de la materia.\\

Las bases sobre las que trabajó Fogel son las siguientes. Se trataba
de predecir el comportamiento de un entorno cambiante dependiente del
tiempo (serie temporal), para intentar tomar acciones en función del
comportamiento esperado del sistema. Se codificaba entonces el estado
del sistema utilizando una secuencia de símbolos cogidos de un
alfabeto finito, y dicha secuencia se lee con un autómata finito, que
produce una salida.\\

La propuesta de Fogel es entonces tener un conjunto de autómatas
finitos, que forman la población de soluciones. Para cada autómata
finito, se evalúa su capacidad de predicción utilizando la salida que
utiliza para la cadena de entrada. Se define una función de adecuación
o \textit{fitness}, que mide el grado de corrección en la predicción
del autómata en ese entorno.\\

Tras tener la población de padres generados de forma aleatoria y
evaluados, se genera un población de hijos ``mutando'' la población de
padres. Cada padre genera un único hijo. Según Fogel, existen cinco
tipos de mutaciones posibles, atendiendo a la descripción de autómata
finito:

\begin{enumerate}
\item Cambiar un símbolo de salida
\item Cambiar una transición de estado
\item Añadir un estado
\item Eliminar un estado
\item Cambiar el estado inicial
\end{enumerate}

Propuso mutaciones más fuertes más adelante, pero no llegó a
implementarlas. Las mutaciones que se producían eran seleccionadas
respecto de una variable aleatoria. Una vez producida la población de
hijos por mutación, se evaluaban de la misma manera que los padres,
Tras esto, entraban en competición los padres con los hijos de forma
que sólo permanecían en la población para generar la siguiente prole
la mitad mejor de los individuos. De esta forma, el tamaño de la
población de padres permanece constante durante todo el algoritmo.
Este proceso de mejora de las predicciones por la población se repetía
hasta que era necesario generar un nuevo símbolo (había que hacer una
predicción nueva). En ese momento, se utilizaba toda la población para
predecir el siguiente símbolo (se tomaba como siguiente símbolo el
símbolo predecido en más ocasiones por la población), se introducía
dicho símbolo en la cadena de entrada, y la nueva cadena se seguía
utilizando para entrenar a la población.

\section{Estrategias de evolución}

\section{Programación genética}


\subsection{Introducción histórica}

La programación genética es un caso particular de algoritmos genéticos
usados para mejorar programas de ordenador de un modo automático.  La
población la componen programas de ordenador (individuos) que se
cruzan unos con otros, y al igual que ocurre con los algoritmos
genéticos y con el paso del tiempo, los mejores individuos sobreviven
y eventualmente evolucionan para mejorar. \\

La primera referencia que se tiene de evolucionar programas es
probablemente la de Alan Turing en la década de los 50. Sin embargo,
pasaron 30 años hasta que Richard Forsyth demostrara el exito en la
evolución de pequeños programas, representados como arboles,
para mejorar la clasificación de las pruebas de una escena de crimen.\\

En 1988 John Koza, estudiante de John Holland, patentó un algoritmo
genético orientado a la evolución de programas, seguido de una
publicación en la International Joint Conference on Artificial
Inteligence. Koza ha sido el exponente principal de la programación
genética aplicando esta a complejos problemas de búsqueda.
En la década de 1990, la programación genética se aplicó 
principalmente para resolver problemas sencillos debido a su alto 
coste computacional.\\

Recientemente la programación genética ha cobrado protagonismo debido 
a los resultados positivos que ha mostrado en áreas como la computación
cuántica, ordenamiento y búsqueda gracias a la potencia de computo de
la que disponemos actualmente. Una de las grandes metas de la ciencia 
de la computación es, dado un problema, que la máquina sea capaz de
construir un programa capaz de resolverlo, y la programación genética
muestra suficiente potencial para conseguirlo en un futuro.\\


\subsection {Creación de la población}

Cada individuo se representa mediante una estructura de árbol, donde 
los nodos no terminales representan funciones cuyos hijos son los 
parámetros que necesita la función como argumento, esto supone un
cambio respecto a los algoritmos genéticos donde los individuos se
representan mediante estructuras lineales como valores reales o
cadenas de bits.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.4\textwidth]{individuo.PNG}
  \caption{Individuo que representa la función \(3\times(x+6)\).}
  \label{fig:dfd:1}
\end{figure}

La elección de los genes disponibles es una tarea importante 
ya que una mala selección podria causar que no evolucione 
la solución.\\

Una vez que los genes han sido seleccionados, se genera una 
poblacion de individuos de forma aleatoria y sin repetición 
como ocurre con los algoritmos genéticos. Koza desarrollo 
tres técnicas para ello: grow,full y ramped-half-and-half.

\subsubsection{Grow}

La población es creada eligiendo una profundidad máxima \(m\),
con esta técnica se crea un individuo nuevo cada vez con una
profundidad no mayor a \(m\),
el proceso se realiza de la siguiente forma:
\begin{itemize}
\item Desde la raiz , cada nodo se elige como función o terminal de
  forma aleatoria.
\item Si el nodo es terminal, se le asigna un nodo terminal de forma
  aleatoria
\item Si el nodo es una función, se le asigna una función de forma
  aleatoria y a ese nodo se le añaden tantos hijos como parámetros
  tenga la función elegida. Para cada hijo se repite el mismo proceso,
  a no ser que ya tenga profundidad \(m\),
  en ese caso para el hijo se selecciona un terminal aleatorio.
\end{itemize}

Esta estrategia genera individuos de profundidad variable no mayor que
\(m\) pero proporciona un rango de variedad muy amplio en la población.

\subsubsection{Full}

Esta estrategia, a diferencia de grow, garantiza que todos los
individuos tienen la misma profundidad, aunque el número de nodos es
variable. Aqui también se necesita especificar una profundidad \(m\),
y el proceso es el siguiente:

Partiendo de la raiz, cada nodo con una profundidad menor que \(m\)
, se convierte en una función aleatoria. Si el nodo tiene profundidad
\(m\) entonces se convierte en un terminal aleatorio. Todas las funciones 
tienen un numero de hijos igual a la cantidad de parámetrosque necesitan 
como argumento. Con esta estrategia te aseguras que todos los individuos 
tienen una profundidad \(m\) aunque por contra la variación es menor 
que con la estrategia grow.\\

\subsubsection{Ramped-half-and-half}

Se propone esta estrategia para aumentar la variación usando las dos
estrategias anteriores. Solo se especifica una profundidad máxima, y
se generan la mitad de los individuos usando el método grow, mientras
que la otra mitad se genera usando el método full, creando asi una
población con una gran diversidad.

\subsection{Función Fitness}

Al igual que ocurre en los algoritmos genéticos, una vez que la
población esta inicializada, los individuos necesitan ser evaluados
para saber lo bueno o malo que es un individuo. La función fitness mas
común es aquella que se adapte de forma más natural al problema que se
plantee. Un ejemplo sería el problema de clasificación donde la
función fitness mas natural seria el número de aciertos.

\subsection{Operadores}

Análogamente a los algoritmos genéticos, la programación genética
cuenta con operadores de selección, cruce y mutación.Actualmente se
consideran otras operaciones como la edición, permutación o el
encapsulamiento , aunque la mayoria de ellas fueron ignoradas por Koza
en sus primeros trabajos.

\subsubsection{Selección}

Para la selección se utilizan los mecanismos habituales de los
algoritmos genéticos, en el caso de la programación genética, Koza
permitía que un 10\% de la poblacón se pudiese reproducir además del
proceso de selección habitual. La función de selección es la encargada
de elegir que individuo se reproduce, cuya reproducción no es mas que
elegir a ese individuo e introducir una copia de el mismo en la
población, si la función fitness es fija, la reproducción tiene un
efecto significativo en el tiempo ya que un individuo generado por
reproducción tendrá el mismo valor fitness que su padre.

\subsubsection{Cruce}

El proceso del operador de cruce es similar al de los algoritmos genéticos, 
en este caso generamos aleatoriamente una arista a cada padre y se 
intercambian los subárboles generando así dos hijos nuevos.\\

Algunas consideraciones a tener en cuenta pueden ser la de no efectuar
el cruce si la profundidad del árbol supera el máximo para evitar que
crezca indefinidamente. Otra consideración posible sería la de
incorporar criterios que penalicen en la función fitness una excesiva
complejidad de los programas.

\subsubsection{Mutación}

La mutación en el caso de la programación genética se puede realizar
de dos formas:

\begin{itemize}
\item Mutación de subárbol: en esta mutación se escoge una arista y se
  sustituye el subárbol conectado a esta por otro generado
  aleatoriamente, sin superar el tamaño máximo establecido.
\item Mutación de punto: se escoge un nodo de forma aleatoria y se
  cambia su valor por otro del mismo tipo, esto se realiza haciendo
  previamente una lista de los terminales y funciones que pueden
  intercambiarse entre si para que sigan siendo individuos válidos.
\end{itemize}

La mutación aqui tiene menos importancia que en los algoritmos
genéticos ya que el operador de cruce es suficiente para mantener la
diversidad.

\subsection{Finalización}

Como conclusión a esta sección añadir que el reemplazo se realiza
sustituyendo la población nueva por la anterior, y el proceso se
repite hasta cumplir el criterio de parada al igual que ocurre en los
algoritmos genéticos, el programa elegido será el mejor de la
población final. El siguiente diagrama de flujo resume todo lo
explicado en la sección.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{FlowchartGP.PNG}
  \caption{Diagrama de flujo de la Programación genética.}
  \label{fig:dfd:1}
\end{figure}


\section{Referencias}
% https://www.cs.montana.edu/~bwall/cs580/introduction_to_gp.pdf
% http://geneticprogramming.com/history/
% https://es.wikipedia.org/wiki/Programaci%C3%B3n_gen%C3%A9tica
% http://sci2s.ugr.es/sites/default/files/files/Teaching/GraduatesCourses/Bioinformatica/Tema%2013%20-%20PG.pdf
% Koza, John R. 1992. Genetic Programming: On the Programming of Computers by Means of Natural Selection. Cambridge, MA: The MIT Press.

\end{document}


